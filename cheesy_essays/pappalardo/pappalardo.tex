%\documentclass[a4paper,11pt,oneside]{amsart}
\documentclass[a4paper,11pt,oneside]{amsart}
\usepackage[pdftex]{hyperref}	%% many PDF options can be set here
% 1 inch margins
\usepackage{fullpage}
\usepackage{fixme}
%\usepackage{times}
\usepackage[small,compact]{titlesec}
% double spaced
\renewcommand{\baselinestretch}{2}
% no page numbers
%\pagestyle {empty}
\hypersetup{ pdfauthor = {Evan K. Friis},
  pdftitle = {Papallardo Fellowship application research proposal},
}

\setlength{\headsep}{0pt}
\title{Searches for Higgs bosons using $\tau$ leptons at the LHC}
\author{Evan K. Friis}
\date{}
\begin{document}
%Outline:
%Paragraph 1:
%Taus are an important probe of Higgs physics:
 %* 10 percent of higgs decays for low mass SM higgs and all of the MSSM
 %* dominant decay mode in these regions is unfeasible to to large backgrounds
 %* 65 percent of taus decay hadronically.
 %* Tau decays before first detector and always contain missing energy in the form of neutrinos.
 %* Tau physics is difficult at hadron colliders because hadronic jets can be
 %misidentified, and because the associated neutrinos are not directly detected. 
 %* We have developed new techniques that dramatically improve tau identification
 %and the reconstruction of the neutrinos.
%Paragraph 2:
%Tau ID
 %* Critical to have high signal efficiency while rejecting multi--jet event
 %events that at a much higher rate.
 %* Traditional approaches at CMS reject QCD jets by applying a geometric isolation
 %requirement.
 %* We introduced a new algorithm called the Tau Neural Classifier (TaNC).
 %* Predicated on the idea that each hadronic decay proceeds through an intermediate
 %resonance.  
 %* An ensemble of neural nets one for each decay mode to classify each decay
 %mode.
 %* At the same signal efficiency as previous algorithm, the background rate is
 %reduced by a factor of four.
 %* For a given tau signal efficiency, the algorithm gives the lowest QCD di--jet
 %mis--tag rate of all published tau identification algorithms at hadron
 %colliders worldwide.
%Paragraph 3:
%Mass reconstruction
 %* In Higgs search natural choice is to search for bumps on Mtautau background.
 %* Difficult as tau momentum not directly reconstructed.  Visible distributions
 %smeared.
 %* Traditionally the  neutrinos are reconstructed by assuming they are collinear with the
 %visible decay products.  however, this approximation fails ~55\% (undetermined or unphysical
 %solutions) and these events must be excluded final fits.
 %* We introduced a new technique called the SV fit, which uses information from
 %the missing energy measurement, tracker information to reconstruct *all*
 %information about the original tau leptons, including displaced secondary
 %information.
 %* Method has 100\% acceptance simultaneously improves the Mtautau resolution by
 %a factor of two w.r.t. the collinear approximation.
%Paragraph 4:
%Plans
 %* New techniques developed will improve the Higgs exclusion limits CMS can set.
 %* Currently working on MSSM AH -> tautau -> mu tau analysis and expect to set
 %new MSSM exclusion limits next summer.
 %* The application of the improved tau ID and SV fit will the Htt analysis in
 %any channel.  
 %* I propose to apply these advanced techniques in other channels of the MSSM
 %Higgs search, initialing the di-hadronic tau decay mode channel.  
 %* Add SM higgs search with more data
 %* I propose to continue improving the SV fit method techniques. 
 %* Polarization information LL/RR Z LR/RL Higgs
 %* Extending to secondary fit to work on events with more than two taus.  
 %* This can improve H++.  
 %* Some dark matter signatures could manifset as production of 2* H+ H+
%\maketitle 
\centerline{\Large \bf  Searches for Higgs bosons using $\tau$ leptons at the LHC} %% Paper title
\centerline{Evan K. Friis}

 \medskip

The $\tau$ lepton is one of the most important probes of Higgs physics. 
Higgs boson decays to $\tau$ lepton pairs are one of the dominant discovery
modes in the Standard Model (SM) when $M_H < 2M_W$, and over the entire
parameter space of the Minimal Super Symmetric Model (MSSM).  Tau leptons decay
almost immediately after being produced.  Their decay products contain one or
two neutrinos which are not directly measured in the detector, and in 65\% of
decays the visible decay products are hadrons.  The invisible and hadronic
component of $\tau$ decays makes using them uniquely challenging at hadron
colliders.  Myself and my colleagues at UC Davis have pioneered new techniques
that address these challenges and will improve the significance of the first searches for
Higgs bosons at the Compact Muon Solenoid (CMS) experiment.  I propose to apply
these techniques to existing analysis channels, investigate previously
infeasible new analyses, and continue development of the methods.

A robust algorithm for identifying hadronic $\tau$ decays is critical to obtain
high acceptance for signal events and a low mis--tag rate for the multi--jet (QCD)
background which is produced at rates $O(10^8)$ times that of the signal.  Past
CMS Higgs analyses have used a geometric isolation requirement to reject QCD
mis--tags.  We introduced a new algorithm called the Tau Neural Classifier
(TaNC), which is motivated by the fact that the different hadronic decay modes
proceed through difference particle resonances.  An ensemble of neural networks
(one for each decay mode) is used to classify $\tau$ candidates.  Tuned to give
the same signal efficiency as the isolation algorithm, the TaNC reduces the
mis--tag background rate by a factor of four.  For a given signal efficiency,
the TaNC has the lowest di--jet mis--tag rate of any published hadron collider
$\tau$-ID algorithm.

In searches for Higgs bosons the natural approach is to look for bumps in the
Drell-Yan and $Z$ boson $\tau$ pair invariant mass spectrum ($M_{\tau\tau}$).
However, a tau lepton can not be directly measured in the detector due to the
neutrino(s) in the decay.  In previous analyses, the neutrinos are reconstructed
by assuming they are collinear with the visible decay products.  This
approximation rejects 55\% of the signal events with undetermined or unphysical
solutions.  The events that pass have poor resolution and non-Gaussian tails.
We developed a new technique called the Secondary Vertex (SV) fit, which uses
information from the CMS tracker, missing energy measurement, and the kinematic
distributions of tau decays.  The method is based on the fact that $\tau$ production
and decay vertices determine the $\tau$ direction and this observable can be
used to reconstruct the neutrino.  The SV fit has 100\% acceptance (all
solutions are physical), and improves the $M_{\tau\tau}$ resolution by more than
a factor of two. This improvement both enlarges \emph{and} sharpens the Higgs
``bump'' and improves separation from the $Z\rightarrow\tau\tau$ background.

The two new techniques described will improve the exclusion limits (or discovery
significance!) that $H\rightarrow\tau\tau$ analyses can set at CMS.  I am
currently participating in an MSSM $H \rightarrow \tau\tau$ search where one
$\tau$ decay contains a $\mu$ and the other decays hadronically. We are
implementing these new techniques in the analysis and plan to set new exclusion
limits on the MSSM this summer.  We expect the limits to be driven by
statistics, and if awarded the fellowship I would continue to participate in
this analysis and improve the limit as more data is produced. The improvements
in identification (TaNC) and mass resolution (SV fit) can enable Higgs searches
previously considered infeasible.  Some notable examples I would pursue as a
Pappalardo fellow include the MSSM/SM case where both taus decay hadronically,
and SM vector boson fusion Higgs searches with early CMS datasets.  Finally, I
propose to study the exciting possibilities for improving the SV fit method.
Due to the difference in spin, the helicities of the $\tau$ leptons are
completely anti-correlated (LR, RL) for $Z$ boson decays, and correlated (LL,
RR) for Higgs boson decays. The likelihoods used in the SV fit are sensitive to
the helicity of the taus, and may provide a handle to separate Higgs from the
(currently irreducible) $Z\rightarrow\tau\tau$ background.  Another promising
extension is using the SV fit for searches with an arbitrary number of $\tau$ 
\nopagebreak leptons.  This could improve charged Higgs searches and open up previously
infeasible channels in multi-Higgs events.  
\end{document}
